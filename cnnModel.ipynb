{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35660c1",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc  # Garbage collector to free memory\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIGURATIONS\n",
    "# -----------------------------\n",
    "OUTPUT_DIR = \"dataset_large\"       # Folder to save images + CSV\n",
    "TOTAL_IMAGES = 5000               # Total dataset size (adjust as needed)\n",
    "BATCH_SIZE = 1000                  # Number of images per batch\n",
    "IMG_SIZE = (28, 28)                # Image resolution\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "csv_path = os.path.join(OUTPUT_DIR, \"tx_parameters.csv\")\n",
    "\n",
    "# Initialize CSV storage\n",
    "if os.path.exists(csv_path):\n",
    "    os.remove(csv_path)\n",
    "\n",
    "# -----------------------------\n",
    "# FUNCTION TO GENERATE WAVEFORM\n",
    "# -----------------------------\n",
    "def generate_waveform(frequency, alpha, beta, dielectric, noise_level=0.02):\n",
    "    \"\"\"Generate synthetic waveform based on transmission line parameters.\"\"\"\n",
    "    t = np.linspace(0, 1, 500)\n",
    "    signal = np.sin(2 * np.pi * frequency * t + beta)\n",
    "    signal *= np.exp(-alpha * t)\n",
    "    noise = noise_level * np.random.randn(len(t))\n",
    "    signal += noise\n",
    "    signal = signal / np.max(np.abs(signal))  # Normalize\n",
    "    return t, signal\n",
    "\n",
    "# -----------------------------\n",
    "# BATCH-WISE DATA GENERATION\n",
    "# -----------------------------\n",
    "print(f\"Generating {TOTAL_IMAGES} waveform images in batches of {BATCH_SIZE}...\")\n",
    "\n",
    "for batch_start in range(0, TOTAL_IMAGES, BATCH_SIZE):\n",
    "    batch_end = min(batch_start + BATCH_SIZE, TOTAL_IMAGES)\n",
    "    batch_data = []\n",
    "\n",
    "    for i in tqdm(range(batch_start, batch_end), desc=f\"Batch {batch_start // BATCH_SIZE + 1}\"):\n",
    "        # Random TX parameters\n",
    "        frequency = np.random.uniform(1e6, 10e9)        # 1 MHz to 10 GHz\n",
    "        alpha = np.random.uniform(0.01, 0.5)            # Attenuation\n",
    "        beta = np.random.uniform(0.1, 2 * np.pi)        # Phase\n",
    "        dielectric = np.random.uniform(1.5, 12.0)       # Permittivity\n",
    "\n",
    "        # Generate waveform\n",
    "        t, signal = generate_waveform(frequency, alpha, beta, dielectric)\n",
    "\n",
    "        # Save image (faster & memory-safe)\n",
    "        img_path = os.path.join(OUTPUT_DIR, f\"waveform_{i}.png\")\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.plot(t, signal, color='blue', linewidth=1.2)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(img_path, dpi=100, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "        # Store metadata\n",
    "        batch_data.append([f\"waveform_{i}.png\", frequency, alpha, beta, dielectric])\n",
    "\n",
    "    # Save batch metadata to CSV\n",
    "    df = pd.DataFrame(batch_data, columns=[\"image\", \"frequency\", \"alpha\", \"beta\", \"dielectric\"])\n",
    "    df.to_csv(csv_path, mode=\"a\", header=not os.path.exists(csv_path), index=False)\n",
    "\n",
    "    # Free memory\n",
    "    del batch_data, df\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"âœ… Saved batch {batch_start // BATCH_SIZE + 1} ({batch_end} images done)\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Dataset generation complete!\")\n",
    "print(f\"ðŸ“‚ Images saved in: {OUTPUT_DIR}\")\n",
    "print(f\"ðŸ“„ Parameters CSV saved at: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa7858d-d105-4a94-a209-364f5e6403e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust_cnn_regression.py\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "DATA_DIR = \"dataset_large\"               # folder with images + tx_parameters.csv\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"tx_parameters.csv\")\n",
    "MODEL_PATH = \"waveform_cnn_best.pth\"\n",
    "SCALER_PATH = \"label_scaler.pkl\"\n",
    "\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32            # safe for RTX 3050 Ti\n",
    "EPOCHS = 60\n",
    "LR = 1e-4\n",
    "PATIENCE = 8               # early stopping patience on val loss\n",
    "CLIP_NORM = 1.0            # gradient clipping\n",
    "VAL_RATIO = 0.1\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_AMP = torch.cuda.is_available()  # use mixed precision only if GPU\n",
    "\n",
    "print(\"Device:\", DEVICE, \"USE_AMP:\", USE_AMP)\n",
    "\n",
    "# -------------------- READ CSV & PREP LABEL SCALING --------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "# Expect CSV columns: [image, frequency, alpha, beta, dielectric]\n",
    "assert df.shape[1] >= 5, \"CSV must contain: filename, frequency, alpha, beta, dielectric\"\n",
    "\n",
    "# prepare lists\n",
    "filenames = df.iloc[:, 0].astype(str).tolist()\n",
    "labels_raw = df.iloc[:, 1:5].values.astype(float)  # shape (N,4)\n",
    "\n",
    "# Transform frequency with log10 to stabilize scale (avoid log(0))\n",
    "labels_trans = labels_raw.copy()\n",
    "labels_trans[:, 0] = np.log10(np.maximum(labels_raw[:, 0], 1.0))  # log10(freq)\n",
    "\n",
    "# Fit a StandardScaler on targets (fit on entire dataset then split; ok for synthetic)\n",
    "label_scaler = StandardScaler()\n",
    "labels_scaled_all = label_scaler.fit_transform(labels_trans)\n",
    "joblib.dump(label_scaler, SCALER_PATH)\n",
    "print(\"Saved label scaler to\", SCALER_PATH)\n",
    "\n",
    "# -------------------- TRAIN/VAL SPLIT --------------------\n",
    "N = len(filenames)\n",
    "indices = np.arange(N)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_count = int(N * VAL_RATIO)\n",
    "val_idx = indices[:val_count]\n",
    "train_idx = indices[val_count:]\n",
    "\n",
    "train_files = [filenames[i] for i in train_idx]\n",
    "val_files   = [filenames[i] for i in val_idx]\n",
    "train_labels = labels_scaled_all[train_idx]\n",
    "val_labels   = labels_scaled_all[val_idx]\n",
    "\n",
    "print(f\"Total samples: {N}, train: {len(train_files)}, val: {len(val_files)}\")\n",
    "\n",
    "# -------------------- DATASET CLASS --------------------\n",
    "class WaveformImageDataset(Dataset):\n",
    "    def __init__(self, file_list, labels_array, img_dir, transform=None):\n",
    "        self.files = file_list\n",
    "        self.labels = labels_array\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        fpath = os.path.join(self.img_dir, fname)\n",
    "        image = Image.open(fpath).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return image, label\n",
    "\n",
    "# -------------------- TRANSFORMS & DATALOADERS --------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),                         # -> [0,1]\n",
    "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])  # -> [-1,1]\n",
    "])\n",
    "\n",
    "train_dataset = WaveformImageDataset(train_files, train_labels, DATA_DIR, transform=transform)\n",
    "val_dataset   = WaveformImageDataset(val_files, val_labels, DATA_DIR, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=0, pin_memory=(DEVICE.type==\"cuda\"))\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=0, pin_memory=(DEVICE.type==\"cuda\"))\n",
    "\n",
    "# -------------------- MODEL --------------------\n",
    "class WaveformCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128,256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((4,4)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*4*4, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(128, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = WaveformCNN().to(DEVICE)\n",
    "\n",
    "# weight init\n",
    "def init_weights(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "model.apply(init_weights)\n",
    "\n",
    "# -------------------- LOSS, OPTIMIZER, SCHEDULER --------------------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=4, verbose=True)\n",
    "\n",
    "scaler = None\n",
    "if USE_AMP:\n",
    "    from torch.amp import GradScaler, autocast\n",
    "    scaler = GradScaler(device=\"cuda\")\n",
    "\n",
    "# -------------------- TRAIN + VALIDATE --------------------\n",
    "best_val = float(\"inf\")\n",
    "best_epoch = -1\n",
    "start_time = time.time()\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    n_train = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} [train]\")\n",
    "    for imgs, lbls in loop:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        lbls = lbls.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if USE_AMP:\n",
    "            with autocast(device_type=\"cuda\"):\n",
    "                preds = model(imgs)\n",
    "                loss = criterion(preds, lbls)\n",
    "            scaler.scale(loss).backward()\n",
    "            # gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, lbls)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss += float(loss.item()) * imgs.size(0)\n",
    "        n_train += imgs.size(0)\n",
    "        loop.set_postfix(train_loss=train_loss / n_train)\n",
    "\n",
    "    train_loss = train_loss / n_train\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    n_val = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            lbls = lbls.to(DEVICE, non_blocking=True)\n",
    "            if USE_AMP:\n",
    "                with autocast(device_type=\"cuda\"):\n",
    "                    preds = model(imgs)\n",
    "                    loss = criterion(preds, lbls)\n",
    "            else:\n",
    "                preds = model(imgs)\n",
    "                loss = criterion(preds, lbls)\n",
    "            val_loss += float(loss.item()) * imgs.size(0)\n",
    "            n_val += imgs.size(0)\n",
    "    val_loss = val_loss / n_val\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss={train_loss:.6e}, val_loss={val_loss:.6e}\")\n",
    "\n",
    "    # scheduler step (ReduceLROnPlateau)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # early stopping & save best\n",
    "    if val_loss < best_val - 1e-12:\n",
    "        best_val = val_loss\n",
    "        best_epoch = epoch\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"Saved best model (epoch {epoch}) val_loss={val_loss:.6e}\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        print(f\"No improvement count: {no_improve}/{PATIENCE}\")\n",
    "\n",
    "    if no_improve >= PATIENCE:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training finished. Best epoch: {best_epoch}, best val loss: {best_val:.6e}, total_time={total_time:.1f}s\")\n",
    "\n",
    "# -------------------- HELPER: Prediction (loads scaler & model) --------------------\n",
    "def load_model_and_scaler(model_path=MODEL_PATH, scaler_path=SCALER_PATH, device=DEVICE):\n",
    "    m = WaveformCNN().to(device)\n",
    "    m.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    m.eval()\n",
    "    scl = joblib.load(scaler_path)\n",
    "    return m, scl\n",
    "\n",
    "def predict_image(image_path, model_obj, scaler_obj, img_size=IMG_SIZE, device=DEVICE):\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ])\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    x = trans(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        if USE_AMP:\n",
    "            from torch.amp import autocast\n",
    "            with autocast(device_type=\"cuda\"):\n",
    "                pred_scaled = model_obj(x).cpu().numpy()\n",
    "        else:\n",
    "            pred_scaled = model_obj(x).cpu().numpy()\n",
    "    # inverse scale and inverse log on frequency\n",
    "    pred_unscaled = scaler_obj.inverse_transform(pred_scaled)\n",
    "    pred_unscaled[:,0] = 10 ** pred_unscaled[:,0]  # inverse log10 frequency\n",
    "    return pred_unscaled.flatten()\n",
    "\n",
    "# Example usage after training:\n",
    "# model_loaded, scaler_loaded = load_model_and_scaler()\n",
    "# print(predict_image(\"dataset_large/waveform_0.png\", model_loaded, scaler_loaded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ee9eb-aa8c-422a-843d-fd804b8c8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_compare.py\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# ====== CONFIG (matches your files) ======\n",
    "DATA_DIR    = \"dataset_large\"                    # folder containing images + csv\n",
    "CSV_PATH    = os.path.join(DATA_DIR, \"tx_parameters.csv\")\n",
    "MODEL_PATH  = \"waveform_cnn_best.pth\"            # model saved during training\n",
    "SCALER_PATH = \"label_scaler.pkl\"                 # label scaler saved during training\n",
    "\n",
    "IMG_SIZE = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "# ====== Model class â€” must match training exactly ======\n",
    "class WaveformCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128,256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((4,4)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*4*4, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(128, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "# =======================================================\n",
    "\n",
    "\n",
    "# ====== Load model & scaler (robust) ======\n",
    "def load_model_and_scaler(model_path=MODEL_PATH, scaler_path=SCALER_PATH, device=DEVICE):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    if not os.path.exists(scaler_path):\n",
    "        raise FileNotFoundError(f\"Scaler file not found: {scaler_path}\")\n",
    "\n",
    "    model = WaveformCNN().to(device)\n",
    "    # safe load: try torch.load with weights_only if available, else standard load\n",
    "    try:\n",
    "        # newer torch supports weights_only argument\n",
    "        state = torch.load(model_path, map_location=device, weights_only=True)\n",
    "    except TypeError:\n",
    "        # fallback (older torch)\n",
    "        state = torch.load(model_path, map_location=device)\n",
    "    # If saved state was state_dict (most likely), load it\n",
    "    if isinstance(state, dict):\n",
    "        model.load_state_dict(state)\n",
    "    else:\n",
    "        # In case model was saved differently, try strict=False as fallback\n",
    "        try:\n",
    "            model.load_state_dict(state.state_dict())\n",
    "        except Exception:\n",
    "            model.load_state_dict(state, strict=False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # load scaler (joblib)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "    return model, scaler\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "# ====== Image transform (match training) ======\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "])\n",
    "# ===========================================\n",
    "\n",
    "\n",
    "# ====== Predict a single image: returns unscaled values (original units) ======\n",
    "def predict_image(image_path, model, scaler, device=DEVICE):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0).to(device)          # shape (1,3,H,W)\n",
    "    with torch.no_grad():\n",
    "        out_scaled = model(x).cpu().numpy()            # shape (1,4)\n",
    "    # inverse transform labels: scaler was fitted to [log10(freq), alpha, beta, dielectric]\n",
    "    out_unscaled = scaler.inverse_transform(out_scaled)  # shape (1,4)\n",
    "    # inverse log10 for frequency:\n",
    "    out_unscaled[0,0] = 10 ** out_unscaled[0,0]\n",
    "    return out_unscaled.flatten()   # [freq, alpha, beta, dielectric]\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "# ====== Compare predictions for random samples from CSV ======\n",
    "def predict_and_compare(n_samples=5, csv_path=CSV_PATH, img_dir=DATA_DIR):\n",
    "    # load model + scaler\n",
    "    model, scaler = load_model_and_scaler()\n",
    "\n",
    "    # load CSV\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"CSV not found: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # ensure expected columns\n",
    "    # first column should be image filename, next four = frequency, alpha, beta, dielectric\n",
    "    # try to infer names gracefully\n",
    "    cols = df.columns.tolist()\n",
    "    if len(cols) < 5:\n",
    "        raise ValueError(\"CSV must have at least 5 columns: image, frequency, alpha, beta, dielectric\")\n",
    "    img_col = cols[0]\n",
    "    label_cols = cols[1:5]\n",
    "\n",
    "    sample_df = df.sample(n=min(n_samples, len(df)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "    for idx, row in sample_df.iterrows():\n",
    "        img_name = str(row[img_col])\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: image not found, skipping: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        true_vals = row[label_cols].astype(float).values  # [freq, alpha, beta, dielectric]\n",
    "        pred_vals = predict_image(img_path, model, scaler)\n",
    "\n",
    "        # print numeric comparison\n",
    "        print(f\"\\nSample {idx+1}: {img_name}\")\n",
    "        print(\"  Actual   -> Frequency: {:.6e}, Alpha: {:.6e}, Beta: {:.6e}, Dielectric: {:.6e}\".format(*true_vals))\n",
    "        print(\"  Predicted-> Frequency: {:.6e}, Alpha: {:.6e}, Beta: {:.6e}, Dielectric: {:.6e}\".format(*pred_vals))\n",
    "\n",
    "        # Plot: image + actual vs predicted (log y-scale so small values are visible)\n",
    "        labels = [\"Freq\", \"Alpha\", \"Beta\", \"Dielectric\"]\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "        # show image\n",
    "        axes[0].imshow(Image.open(img_path).convert(\"RGB\"))\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[0].set_title(img_name)\n",
    "\n",
    "        # bar chart: use log scale on y\n",
    "        x = np.arange(len(labels))\n",
    "        axes[1].bar(x - 0.2, true_vals, width=0.4, label=\"Actual\", color=\"tab:blue\")\n",
    "        axes[1].bar(x + 0.2, pred_vals, width=0.4, label=\"Pred\", color=\"tab:orange\", alpha=0.8)\n",
    "        axes[1].set_xticks(x)\n",
    "        axes[1].set_xticklabels(labels)\n",
    "        axes[1].set_yscale(\"log\")\n",
    "        axes[1].set_title(\"Actual vs Predicted (log scale)\")\n",
    "        axes[1].legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # change n_samples if you want to display more/less\n",
    "    predict_and_compare(n_samples=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6239c68a-3bff-4270-b3e8-92b66a419fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "LARGE_DIR = \"dataset_large\"\n",
    "SAMPLE_DIR = \"dataset_sample\"\n",
    "CSV_PATH = os.path.join(LARGE_DIR, \"tx_parameters.csv\")\n",
    "SAMPLE_CSV_PATH = os.path.join(SAMPLE_DIR, \"tx_parameters_sample.csv\")\n",
    "\n",
    "# Make sample folder\n",
    "os.makedirs(SAMPLE_DIR, exist_ok=True)\n",
    "\n",
    "# Load full CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Pick 10 samples (first 10, or you can shuffle for random)\n",
    "sample_df = df.head(10)   # use df.sample(10, random_state=42) for random\n",
    "\n",
    "# Copy images\n",
    "for img_name in sample_df[\"image\"]:\n",
    "    src = os.path.join(LARGE_DIR, img_name)\n",
    "    dst = os.path.join(SAMPLE_DIR, img_name)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "# Save sample CSV\n",
    "sample_df.to_csv(SAMPLE_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"âœ… 10 sample images + CSV saved in: {SAMPLE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c4243-2301-4052-af07-86968ad46317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import joblib\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "DATA_DIR = \"dataset_large\"\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"tx_parameters.csv\")\n",
    "MODEL_PATH = \"waveform_cnn_best.pth\"\n",
    "SCALER_PATH = \"label_scaler.pkl\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMG_SIZE = 64\n",
    "USE_AMP = torch.cuda.is_available()\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# -------------------- MODEL --------------------\n",
    "class WaveformCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128,256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((4,4)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*4*4, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(128, 4)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# -------------------- LOAD MODEL + SCALER --------------------\n",
    "model = WaveformCNN().to(DEVICE)\n",
    "\n",
    "# Safe load with weights_only=True (PyTorch 2.1+)\n",
    "state_dict = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "# -------------------- PREDICTION FUNCTION --------------------\n",
    "def predict_image(image_path, model_obj=model, scaler_obj=scaler, img_size=IMG_SIZE, device=DEVICE):\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ])\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    x = trans(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if USE_AMP:\n",
    "            from torch.amp import autocast\n",
    "            with autocast(device_type=\"cuda\"):\n",
    "                pred_scaled = model_obj(x).cpu().numpy()\n",
    "        else:\n",
    "            pred_scaled = model_obj(x).cpu().numpy()\n",
    "\n",
    "    # inverse scale\n",
    "    pred_unscaled = scaler_obj.inverse_transform(pred_scaled)\n",
    "\n",
    "    # fix overflow in frequency inverse log\n",
    "    pred_unscaled[:,0] = 10 ** np.clip(pred_unscaled[:,0], 0, 12)\n",
    "\n",
    "    return pred_unscaled.flatten()\n",
    "\n",
    "# -------------------- EVALUATE ACCURACY --------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "best_idx = -1\n",
    "best_name = None\n",
    "best_err = float(\"inf\")\n",
    "best_gt = None\n",
    "best_pred = None\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Evaluating\"):\n",
    "    img_name = row[\"image\"]\n",
    "    gt_values = row[[\"frequency\", \"alpha\", \"beta\", \"dielectric\"]].values.astype(float)\n",
    "\n",
    "    pred_values = predict_image(os.path.join(DATA_DIR, img_name))\n",
    "\n",
    "    # safe denominator (avoid overflow / div by 0)\n",
    "    denom = np.maximum(np.maximum(np.abs(gt_values), np.abs(pred_values)), 1e-9)\n",
    "    rel_error = np.abs(pred_values - gt_values) / denom\n",
    "    mean_error = rel_error.mean()\n",
    "\n",
    "    if mean_error < best_err:\n",
    "        best_err = mean_error\n",
    "        best_idx = idx\n",
    "        best_name = img_name\n",
    "        best_gt = gt_values\n",
    "        best_pred = pred_values\n",
    "\n",
    "# -------------------- RESULT --------------------\n",
    "print(\"\\nðŸŽ¯ Most Accurate Prediction Found:\")\n",
    "print(f\"Image index: {best_idx}, Filename: {best_name}\")\n",
    "print(f\"Ground Truth : {best_gt}\")\n",
    "print(f\"Prediction   : {best_pred}\")\n",
    "print(f\"Relative Error % per param: {(100* np.abs(best_pred - best_gt) / np.maximum(np.maximum(np.abs(best_gt), np.abs(best_pred)), 1e-9)).round(3)}\")\n",
    "print(f\"Mean Relative Error %: {best_err*100:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646e986-d1cf-43a9-b23e-d0cdf9524947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tx_env)",
   "language": "python",
   "name": "tx_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
